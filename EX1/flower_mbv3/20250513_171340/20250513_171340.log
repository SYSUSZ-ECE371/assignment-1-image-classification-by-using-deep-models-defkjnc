2025/05/13 17:13:40 - mmengine - INFO - 
------------------------------------------------------------
System environment:
    sys.platform: win32
    Python: 3.8.20 | packaged by conda-forge | (default, Sep 30 2024, 17:44:03) [MSC v.1929 64 bit (AMD64)]
    CUDA available: False
    MUSA available: False
    numpy_random_seed: 49276436
    GCC: n/a
    PyTorch: 2.2.2+cpu
    PyTorch compiling details: PyTorch built with:
  - C++ Version: 201703
  - MSVC 192930151
  - Intel(R) Math Kernel Library Version 2020.0.2 Product Build 20200624 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.3.2 (Git Hash 2dc95a2ad0841e29db8b22fbccaf3e5da7992b01)
  - OpenMP 2019
  - LAPACK is enabled (usually provided by MKL)
  - CPU capability usage: AVX2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CXX_COMPILER=C:/actions-runner/_work/pytorch/pytorch/builder/windows/tmp_bin/sccache-cl.exe, CXX_FLAGS=/DWIN32 /D_WINDOWS /GR /EHsc /Zc:__cplusplus /bigobj /FS /utf-8 -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOCUPTI -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE /wd4624 /wd4068 /wd4067 /wd4267 /wd4661 /wd4717 /wd4244 /wd4804 /wd4273, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.2.2, USE_CUDA=0, USE_CUDNN=OFF, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=OFF, USE_NNPACK=OFF, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

    TorchVision: 0.17.2+cpu
    OpenCV: 4.11.0
    MMEngine: 0.10.7

Runtime environment:
    cudnn_benchmark: False
    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}
    dist_cfg: {'backend': 'nccl'}
    seed: 49276436
    deterministic: False
    Distributed launcher: none
    Distributed training: False
    GPU number: 1
------------------------------------------------------------

2025/05/13 17:13:41 - mmengine - INFO - Config:
auto_scale_lr = dict(base_batch_size=256)
data_root = 'data/flower_dataset'
default_hooks = dict(
    checkpoint=dict(interval=1, type='CheckpointHook'),
    logger=dict(interval=100, type='LoggerHook'),
    param_scheduler=dict(type='ParamSchedulerHook'),
    sampler_seed=dict(type='DistSamplerSeedHook'),
    timer=dict(type='IterTimerHook'),
    visualization=dict(enable=False, type='VisualizationHook'))
default_scope = 'mmpretrain'
env_cfg = dict(
    cudnn_benchmark=False,
    dist_cfg=dict(backend='nccl'),
    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))
launcher = 'none'
load_from = 'checkpoints/mobilenet-v3-small_8xb128_in1k_20221114-bd1bfcde.pth'
log_level = 'INFO'
model = dict(
    backbone=dict(arch='small', type='MobileNetV3'),
    head=dict(
        act_cfg=dict(type='HSwish'),
        dropout_rate=0.2,
        in_channels=576,
        init_cfg=dict(
            bias=0.0, layer='Linear', mean=0.0, std=0.01, type='Normal'),
        loss=dict(
            label_smooth_val=0.1, loss_weight=1.0, type='LabelSmoothLoss'),
        mid_channels=[
            1024,
        ],
        num_classes=5,
        topk=(1, ),
        type='StackedLinearClsHead'),
    neck=dict(type='GlobalAveragePooling'),
    type='ImageClassifier')
optim_wrapper = dict(
    optimizer=dict(lr=0.01, momentum=0.9, type='SGD', weight_decay=0.0001))
param_scheduler = [
    dict(begin=0, by_epoch=True, end=5, start_factor=0.1, type='LinearLR'),
    dict(
        T_max=95,
        begin=5,
        by_epoch=True,
        end=100,
        eta_min=1e-05,
        type='CosineAnnealingLR'),
]
randomness = dict(deterministic=False, seed=None)
resume = False
test_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(edge='short', scale=256, type='ResizeEdge'),
    dict(crop_size=224, type='CenterCrop'),
    dict(type='PackInputs'),
]
train_cfg = dict(by_epoch=True, max_epochs=100, val_interval=1)
train_dataloader = dict(
    batch_size=64,
    collate_fn=dict(type='default_collate'),
    dataset=dict(
        ann_file='train.txt',
        classes='data/flower_dataset/classes.txt',
        data_prefix='train',
        data_root='data/flower_dataset',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(scale=224, type='RandomResizedCrop'),
            dict(prob=0.5, type='RandomFlip'),
            dict(type='PackInputs'),
        ],
        type='ImageNet'),
    num_workers=5,
    persistent_workers=True,
    pin_memory=True,
    sampler=dict(shuffle=True, type='DefaultSampler'))
train_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(scale=224, type='RandomResizedCrop'),
    dict(prob=0.5, type='RandomFlip'),
    dict(type='PackInputs'),
]
val_cfg = dict()
val_dataloader = dict(
    batch_size=64,
    collate_fn=dict(type='default_collate'),
    dataset=dict(
        ann_file='val.txt',
        classes='data/flower_dataset/classes.txt',
        data_prefix='val',
        data_root='data/flower_dataset',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(edge='short', scale=256, type='ResizeEdge'),
            dict(crop_size=224, type='CenterCrop'),
            dict(type='PackInputs'),
        ],
        type='ImageNet'),
    num_workers=5,
    persistent_workers=True,
    pin_memory=True,
    sampler=dict(shuffle=False, type='DefaultSampler'))
val_evaluator = dict(topk=(1, ), type='Accuracy')
vis_backends = [
    dict(type='LocalVisBackend'),
]
visualizer = dict(
    type='UniversalVisualizer', vis_backends=[
        dict(type='LocalVisBackend'),
    ])
work_dir = './work_dirs\\flower_mbv3'

2025/05/13 17:13:41 - mmengine - INFO - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.
2025/05/13 17:13:41 - mmengine - INFO - Hooks will be executed in the following order:
before_run:
(VERY_HIGH   ) RuntimeInfoHook                    
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
before_train:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_train_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(NORMAL      ) DistSamplerSeedHook                
 -------------------- 
before_train_iter:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_train_iter:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
after_train_epoch:
(NORMAL      ) IterTimerHook                      
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_val:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
before_val_epoch:
(NORMAL      ) IterTimerHook                      
 -------------------- 
before_val_iter:
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_val_iter:
(NORMAL      ) IterTimerHook                      
(NORMAL      ) VisualizationHook                  
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_val_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
after_val:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
after_train:
(VERY_HIGH   ) RuntimeInfoHook                    
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_test:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
before_test_epoch:
(NORMAL      ) IterTimerHook                      
 -------------------- 
before_test_iter:
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_test_iter:
(NORMAL      ) IterTimerHook                      
(NORMAL      ) VisualizationHook                  
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_test_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_test:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
after_run:
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
Name of parameter - Initialization information

backbone.layer0.conv.weight - torch.Size([16, 3, 3, 3]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer0.bn.weight - torch.Size([16]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer0.bn.bias - torch.Size([16]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer1.depthwise_conv.conv.weight - torch.Size([16, 1, 3, 3]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer1.depthwise_conv.bn.weight - torch.Size([16]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer1.depthwise_conv.bn.bias - torch.Size([16]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer1.se.conv1.conv.weight - torch.Size([8, 16, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer1.se.conv1.conv.bias - torch.Size([8]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer1.se.conv2.conv.weight - torch.Size([16, 8, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer1.se.conv2.conv.bias - torch.Size([16]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer1.linear_conv.conv.weight - torch.Size([16, 16, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer1.linear_conv.bn.weight - torch.Size([16]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer1.linear_conv.bn.bias - torch.Size([16]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer2.expand_conv.conv.weight - torch.Size([72, 16, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer2.expand_conv.bn.weight - torch.Size([72]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer2.expand_conv.bn.bias - torch.Size([72]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer2.depthwise_conv.conv.weight - torch.Size([72, 1, 3, 3]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer2.depthwise_conv.bn.weight - torch.Size([72]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer2.depthwise_conv.bn.bias - torch.Size([72]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer2.linear_conv.conv.weight - torch.Size([24, 72, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer2.linear_conv.bn.weight - torch.Size([24]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer2.linear_conv.bn.bias - torch.Size([24]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.expand_conv.conv.weight - torch.Size([88, 24, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer3.expand_conv.bn.weight - torch.Size([88]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.expand_conv.bn.bias - torch.Size([88]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.depthwise_conv.conv.weight - torch.Size([88, 1, 3, 3]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer3.depthwise_conv.bn.weight - torch.Size([88]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.depthwise_conv.bn.bias - torch.Size([88]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.linear_conv.conv.weight - torch.Size([24, 88, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer3.linear_conv.bn.weight - torch.Size([24]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.linear_conv.bn.bias - torch.Size([24]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer4.expand_conv.conv.weight - torch.Size([96, 24, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer4.expand_conv.bn.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer4.expand_conv.bn.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer4.depthwise_conv.conv.weight - torch.Size([96, 1, 5, 5]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer4.depthwise_conv.bn.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer4.depthwise_conv.bn.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer4.se.conv1.conv.weight - torch.Size([24, 96, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer4.se.conv1.conv.bias - torch.Size([24]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer4.se.conv2.conv.weight - torch.Size([96, 24, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer4.se.conv2.conv.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer4.linear_conv.conv.weight - torch.Size([40, 96, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer4.linear_conv.bn.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer4.linear_conv.bn.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer5.expand_conv.conv.weight - torch.Size([240, 40, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer5.expand_conv.bn.weight - torch.Size([240]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer5.expand_conv.bn.bias - torch.Size([240]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer5.depthwise_conv.conv.weight - torch.Size([240, 1, 5, 5]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer5.depthwise_conv.bn.weight - torch.Size([240]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer5.depthwise_conv.bn.bias - torch.Size([240]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer5.se.conv1.conv.weight - torch.Size([64, 240, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer5.se.conv1.conv.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer5.se.conv2.conv.weight - torch.Size([240, 64, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer5.se.conv2.conv.bias - torch.Size([240]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer5.linear_conv.conv.weight - torch.Size([40, 240, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer5.linear_conv.bn.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer5.linear_conv.bn.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer6.expand_conv.conv.weight - torch.Size([240, 40, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer6.expand_conv.bn.weight - torch.Size([240]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer6.expand_conv.bn.bias - torch.Size([240]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer6.depthwise_conv.conv.weight - torch.Size([240, 1, 5, 5]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer6.depthwise_conv.bn.weight - torch.Size([240]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer6.depthwise_conv.bn.bias - torch.Size([240]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer6.se.conv1.conv.weight - torch.Size([64, 240, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer6.se.conv1.conv.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer6.se.conv2.conv.weight - torch.Size([240, 64, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer6.se.conv2.conv.bias - torch.Size([240]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer6.linear_conv.conv.weight - torch.Size([40, 240, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer6.linear_conv.bn.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer6.linear_conv.bn.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer7.expand_conv.conv.weight - torch.Size([120, 40, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer7.expand_conv.bn.weight - torch.Size([120]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer7.expand_conv.bn.bias - torch.Size([120]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer7.depthwise_conv.conv.weight - torch.Size([120, 1, 5, 5]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer7.depthwise_conv.bn.weight - torch.Size([120]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer7.depthwise_conv.bn.bias - torch.Size([120]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer7.se.conv1.conv.weight - torch.Size([32, 120, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer7.se.conv1.conv.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer7.se.conv2.conv.weight - torch.Size([120, 32, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer7.se.conv2.conv.bias - torch.Size([120]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer7.linear_conv.conv.weight - torch.Size([48, 120, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer7.linear_conv.bn.weight - torch.Size([48]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer7.linear_conv.bn.bias - torch.Size([48]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer8.expand_conv.conv.weight - torch.Size([144, 48, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer8.expand_conv.bn.weight - torch.Size([144]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer8.expand_conv.bn.bias - torch.Size([144]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer8.depthwise_conv.conv.weight - torch.Size([144, 1, 5, 5]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer8.depthwise_conv.bn.weight - torch.Size([144]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer8.depthwise_conv.bn.bias - torch.Size([144]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer8.se.conv1.conv.weight - torch.Size([40, 144, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer8.se.conv1.conv.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer8.se.conv2.conv.weight - torch.Size([144, 40, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer8.se.conv2.conv.bias - torch.Size([144]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer8.linear_conv.conv.weight - torch.Size([48, 144, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer8.linear_conv.bn.weight - torch.Size([48]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer8.linear_conv.bn.bias - torch.Size([48]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer9.expand_conv.conv.weight - torch.Size([288, 48, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer9.expand_conv.bn.weight - torch.Size([288]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer9.expand_conv.bn.bias - torch.Size([288]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer9.depthwise_conv.conv.weight - torch.Size([288, 1, 5, 5]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer9.depthwise_conv.bn.weight - torch.Size([288]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer9.depthwise_conv.bn.bias - torch.Size([288]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer9.se.conv1.conv.weight - torch.Size([72, 288, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer9.se.conv1.conv.bias - torch.Size([72]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer9.se.conv2.conv.weight - torch.Size([288, 72, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer9.se.conv2.conv.bias - torch.Size([288]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer9.linear_conv.conv.weight - torch.Size([96, 288, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer9.linear_conv.bn.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer9.linear_conv.bn.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer10.expand_conv.conv.weight - torch.Size([576, 96, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer10.expand_conv.bn.weight - torch.Size([576]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer10.expand_conv.bn.bias - torch.Size([576]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer10.depthwise_conv.conv.weight - torch.Size([576, 1, 5, 5]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer10.depthwise_conv.bn.weight - torch.Size([576]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer10.depthwise_conv.bn.bias - torch.Size([576]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer10.se.conv1.conv.weight - torch.Size([144, 576, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer10.se.conv1.conv.bias - torch.Size([144]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer10.se.conv2.conv.weight - torch.Size([576, 144, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer10.se.conv2.conv.bias - torch.Size([576]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer10.linear_conv.conv.weight - torch.Size([96, 576, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer10.linear_conv.bn.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer10.linear_conv.bn.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer11.expand_conv.conv.weight - torch.Size([576, 96, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer11.expand_conv.bn.weight - torch.Size([576]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer11.expand_conv.bn.bias - torch.Size([576]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer11.depthwise_conv.conv.weight - torch.Size([576, 1, 5, 5]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer11.depthwise_conv.bn.weight - torch.Size([576]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer11.depthwise_conv.bn.bias - torch.Size([576]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer11.se.conv1.conv.weight - torch.Size([144, 576, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer11.se.conv1.conv.bias - torch.Size([144]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer11.se.conv2.conv.weight - torch.Size([576, 144, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer11.se.conv2.conv.bias - torch.Size([576]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer11.linear_conv.conv.weight - torch.Size([96, 576, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer11.linear_conv.bn.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer11.linear_conv.bn.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer12.conv.weight - torch.Size([576, 96, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer12.bn.weight - torch.Size([576]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer12.bn.bias - torch.Size([576]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

head.layers.0.fc.weight - torch.Size([1024, 576]): 
NormalInit: mean=0.0, std=0.01, bias=0.0 

head.layers.0.fc.bias - torch.Size([1024]): 
NormalInit: mean=0.0, std=0.01, bias=0.0 

head.layers.1.fc.weight - torch.Size([5, 1024]): 
NormalInit: mean=0.0, std=0.01, bias=0.0 

head.layers.1.fc.bias - torch.Size([5]): 
NormalInit: mean=0.0, std=0.01, bias=0.0 
2025/05/13 17:13:41 - mmengine - INFO - Load checkpoint from checkpoints/mobilenet-v3-small_8xb128_in1k_20221114-bd1bfcde.pth
2025/05/13 17:13:41 - mmengine - WARNING - "FileClient" will be deprecated in future. Please use io functions in https://mmengine.readthedocs.io/en/latest/api/fileio.html#file-io
2025/05/13 17:13:41 - mmengine - WARNING - "HardDiskBackend" is the alias of "LocalBackend" and the former will be deprecated in future.
2025/05/13 17:13:41 - mmengine - INFO - Checkpoints will be saved to C:\Users\PC\mmpretrain\work_dirs\flower_mbv3.
2025/05/13 17:14:23 - mmengine - INFO - Exp name: flower_mbv3_20250513_171340
2025/05/13 17:14:23 - mmengine - INFO - Epoch(train)   [1][36/36]  lr: 1.0000e-03  eta: 1:08:05  time: 0.8156  data_time: 0.0002  loss: 1.2032
2025/05/13 17:14:23 - mmengine - INFO - Saving checkpoint at 1 epochs
2025/05/13 17:14:34 - mmengine - INFO - Epoch(val) [1][9/9]    accuracy/top1: 54.7203  data_time: 1.0393  time: 1.2500
2025/05/13 17:15:05 - mmengine - INFO - Exp name: flower_mbv3_20250513_171340
2025/05/13 17:15:05 - mmengine - INFO - Epoch(train)   [2][36/36]  lr: 3.2500e-03  eta: 0:58:36  time: 0.8167  data_time: 0.0016  loss: 0.7622
2025/05/13 17:15:05 - mmengine - INFO - Saving checkpoint at 2 epochs
2025/05/13 17:15:07 - mmengine - INFO - Epoch(val) [2][9/9]    accuracy/top1: 78.1469  data_time: 0.0119  time: 0.2229
2025/05/13 17:15:38 - mmengine - INFO - Exp name: flower_mbv3_20250513_171340
2025/05/13 17:15:38 - mmengine - INFO - Epoch(train)   [3][36/36]  lr: 5.5000e-03  eta: 0:55:18  time: 0.8221  data_time: 0.0024  loss: 0.6497
2025/05/13 17:15:38 - mmengine - INFO - Saving checkpoint at 3 epochs
2025/05/13 17:15:40 - mmengine - INFO - Epoch(val) [3][9/9]    accuracy/top1: 86.7133  data_time: 0.0112  time: 0.2149
