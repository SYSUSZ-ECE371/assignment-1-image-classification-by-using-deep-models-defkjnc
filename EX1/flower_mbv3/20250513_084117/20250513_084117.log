2025/05/13 08:41:17 - mmengine - INFO - 
------------------------------------------------------------
System environment:
    sys.platform: win32
    Python: 3.8.20 | packaged by conda-forge | (default, Sep 30 2024, 17:44:03) [MSC v.1929 64 bit (AMD64)]
    CUDA available: False
    MUSA available: False
    numpy_random_seed: 1105720861
    GCC: n/a
    PyTorch: 2.2.2+cpu
    PyTorch compiling details: PyTorch built with:
  - C++ Version: 201703
  - MSVC 192930151
  - Intel(R) Math Kernel Library Version 2020.0.2 Product Build 20200624 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.3.2 (Git Hash 2dc95a2ad0841e29db8b22fbccaf3e5da7992b01)
  - OpenMP 2019
  - LAPACK is enabled (usually provided by MKL)
  - CPU capability usage: AVX2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CXX_COMPILER=C:/actions-runner/_work/pytorch/pytorch/builder/windows/tmp_bin/sccache-cl.exe, CXX_FLAGS=/DWIN32 /D_WINDOWS /GR /EHsc /Zc:__cplusplus /bigobj /FS /utf-8 -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOCUPTI -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE /wd4624 /wd4068 /wd4067 /wd4267 /wd4661 /wd4717 /wd4244 /wd4804 /wd4273, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.2.2, USE_CUDA=0, USE_CUDNN=OFF, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=OFF, USE_NNPACK=OFF, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

    TorchVision: 0.17.2+cpu
    OpenCV: 4.11.0
    MMEngine: 0.10.7

Runtime environment:
    cudnn_benchmark: False
    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}
    dist_cfg: {'backend': 'nccl'}
    seed: 1105720861
    deterministic: False
    Distributed launcher: none
    Distributed training: False
    GPU number: 1
------------------------------------------------------------

2025/05/13 08:41:17 - mmengine - INFO - Config:
auto_scale_lr = dict(base_batch_size=256)
default_hooks = dict(
    checkpoint=dict(interval=1, type='CheckpointHook'),
    logger=dict(interval=100, type='LoggerHook'),
    param_scheduler=dict(type='ParamSchedulerHook'),
    sampler_seed=dict(type='DistSamplerSeedHook'),
    timer=dict(type='IterTimerHook'),
    visualization=dict(enable=False, type='VisualizationHook'))
default_scope = 'mmpretrain'
env_cfg = dict(
    cudnn_benchmark=False,
    dist_cfg=dict(backend='nccl'),
    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))
launcher = 'none'
load_from = 'work_dirs/flower_mbv3/epoch_20.pth'
log_level = 'INFO'
model = dict(
    backbone=dict(arch='small', type='MobileNetV3'),
    head=dict(
        act_cfg=dict(type='HSwish'),
        dropout_rate=0.2,
        in_channels=576,
        init_cfg=dict(
            bias=0.0, layer='Linear', mean=0.0, std=0.01, type='Normal'),
        loss=dict(loss_weight=1.0, type='CrossEntropyLoss'),
        mid_channels=[
            1024,
        ],
        num_classes=5,
        topk=(1, ),
        type='StackedLinearClsHead'),
    neck=dict(type='GlobalAveragePooling'),
    type='ImageClassifier')
optim_wrapper = dict(
    optimizer=dict(lr=0.1, momentum=0.9, type='SGD', weight_decay=0.0001))
optimizer = dict(
    betas=(
        0.9,
        0.999,
    ), lr=0.001, type='AdamW', weight_decay=0.05)
param_scheduler = [
    dict(begin=0, by_epoch=True, end=5, start_factor=0.1, type='LinearLR'),
    dict(
        T_max=35,
        begin=5,
        by_epoch=True,
        end=40,
        eta_min=0.0001,
        type='CosineAnnealingLR'),
]
randomness = dict(deterministic=False, seed=None)
resume = True
test_cfg = dict()
test_dataloader = dict(
    batch_size=32,
    collate_fn=dict(type='default_collate'),
    dataset=dict(
        classes='data/flower_dataset/classes.txt',
        data_prefix='val',
        data_root='data/flower_dataset',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(edge='short', scale=256, type='ResizeEdge'),
            dict(crop_size=224, type='CenterCrop'),
            dict(type='PackInputs'),
        ],
        type='ImageNet'),
    num_workers=4,
    persistent_workers=True,
    pin_memory=True,
    sampler=dict(shuffle=False, type='DefaultSampler'))
test_evaluator = dict(topk=(1, ), type='Accuracy')
test_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(edge='short', scale=256, type='ResizeEdge'),
    dict(crop_size=224, type='CenterCrop'),
    dict(type='PackInputs'),
]
train_cfg = dict(by_epoch=True, max_epochs=40, val_interval=1)
train_dataloader = dict(
    batch_size=32,
    collate_fn=dict(type='default_collate'),
    dataset=dict(
        classes='data/flower_dataset/classes.txt',
        data_prefix='train',
        data_root='data/flower_dataset',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(scale=224, type='RandomResizedCrop'),
            dict(direction='horizontal', prob=0.5, type='RandomFlip'),
            dict(type='PackInputs'),
        ],
        type='ImageNet'),
    num_workers=4,
    persistent_workers=True,
    pin_memory=True,
    sampler=dict(shuffle=True, type='DefaultSampler'))
train_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(scale=224, type='RandomResizedCrop'),
    dict(direction='horizontal', prob=0.5, type='RandomFlip'),
    dict(type='PackInputs'),
]
val_cfg = dict()
val_dataloader = dict(
    batch_size=32,
    collate_fn=dict(type='default_collate'),
    dataset=dict(
        classes='data/flower_dataset/classes.txt',
        data_prefix='val',
        data_root='data/flower_dataset',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(edge='short', scale=256, type='ResizeEdge'),
            dict(crop_size=224, type='CenterCrop'),
            dict(type='PackInputs'),
        ],
        type='ImageNet'),
    num_workers=4,
    persistent_workers=True,
    pin_memory=True,
    sampler=dict(shuffle=False, type='DefaultSampler'))
val_evaluator = dict(topk=(1, ), type='Accuracy')
vis_backends = [
    dict(type='LocalVisBackend'),
]
visualizer = dict(
    type='UniversalVisualizer', vis_backends=[
        dict(type='LocalVisBackend'),
    ])
work_dir = 'work_dirs/flower_mbv3'

2025/05/13 08:41:18 - mmengine - INFO - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.
2025/05/13 08:41:18 - mmengine - INFO - Hooks will be executed in the following order:
before_run:
(VERY_HIGH   ) RuntimeInfoHook                    
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
before_train:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_train_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(NORMAL      ) DistSamplerSeedHook                
 -------------------- 
before_train_iter:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_train_iter:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
after_train_epoch:
(NORMAL      ) IterTimerHook                      
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_val:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
before_val_epoch:
(NORMAL      ) IterTimerHook                      
 -------------------- 
before_val_iter:
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_val_iter:
(NORMAL      ) IterTimerHook                      
(NORMAL      ) VisualizationHook                  
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_val_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
after_val:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
after_train:
(VERY_HIGH   ) RuntimeInfoHook                    
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_test:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
before_test_epoch:
(NORMAL      ) IterTimerHook                      
 -------------------- 
before_test_iter:
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_test_iter:
(NORMAL      ) IterTimerHook                      
(NORMAL      ) VisualizationHook                  
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_test_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_test:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
after_run:
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
Name of parameter - Initialization information

backbone.layer0.conv.weight - torch.Size([16, 3, 3, 3]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer0.bn.weight - torch.Size([16]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer0.bn.bias - torch.Size([16]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer1.depthwise_conv.conv.weight - torch.Size([16, 1, 3, 3]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer1.depthwise_conv.bn.weight - torch.Size([16]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer1.depthwise_conv.bn.bias - torch.Size([16]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer1.se.conv1.conv.weight - torch.Size([8, 16, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer1.se.conv1.conv.bias - torch.Size([8]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer1.se.conv2.conv.weight - torch.Size([16, 8, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer1.se.conv2.conv.bias - torch.Size([16]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer1.linear_conv.conv.weight - torch.Size([16, 16, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer1.linear_conv.bn.weight - torch.Size([16]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer1.linear_conv.bn.bias - torch.Size([16]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer2.expand_conv.conv.weight - torch.Size([72, 16, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer2.expand_conv.bn.weight - torch.Size([72]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer2.expand_conv.bn.bias - torch.Size([72]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer2.depthwise_conv.conv.weight - torch.Size([72, 1, 3, 3]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer2.depthwise_conv.bn.weight - torch.Size([72]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer2.depthwise_conv.bn.bias - torch.Size([72]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer2.linear_conv.conv.weight - torch.Size([24, 72, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer2.linear_conv.bn.weight - torch.Size([24]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer2.linear_conv.bn.bias - torch.Size([24]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.expand_conv.conv.weight - torch.Size([88, 24, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer3.expand_conv.bn.weight - torch.Size([88]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.expand_conv.bn.bias - torch.Size([88]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.depthwise_conv.conv.weight - torch.Size([88, 1, 3, 3]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer3.depthwise_conv.bn.weight - torch.Size([88]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.depthwise_conv.bn.bias - torch.Size([88]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.linear_conv.conv.weight - torch.Size([24, 88, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer3.linear_conv.bn.weight - torch.Size([24]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.linear_conv.bn.bias - torch.Size([24]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer4.expand_conv.conv.weight - torch.Size([96, 24, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer4.expand_conv.bn.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer4.expand_conv.bn.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer4.depthwise_conv.conv.weight - torch.Size([96, 1, 5, 5]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer4.depthwise_conv.bn.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer4.depthwise_conv.bn.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer4.se.conv1.conv.weight - torch.Size([24, 96, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer4.se.conv1.conv.bias - torch.Size([24]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer4.se.conv2.conv.weight - torch.Size([96, 24, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer4.se.conv2.conv.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer4.linear_conv.conv.weight - torch.Size([40, 96, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer4.linear_conv.bn.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer4.linear_conv.bn.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer5.expand_conv.conv.weight - torch.Size([240, 40, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer5.expand_conv.bn.weight - torch.Size([240]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer5.expand_conv.bn.bias - torch.Size([240]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer5.depthwise_conv.conv.weight - torch.Size([240, 1, 5, 5]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer5.depthwise_conv.bn.weight - torch.Size([240]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer5.depthwise_conv.bn.bias - torch.Size([240]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer5.se.conv1.conv.weight - torch.Size([64, 240, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer5.se.conv1.conv.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer5.se.conv2.conv.weight - torch.Size([240, 64, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer5.se.conv2.conv.bias - torch.Size([240]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer5.linear_conv.conv.weight - torch.Size([40, 240, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer5.linear_conv.bn.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer5.linear_conv.bn.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer6.expand_conv.conv.weight - torch.Size([240, 40, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer6.expand_conv.bn.weight - torch.Size([240]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer6.expand_conv.bn.bias - torch.Size([240]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer6.depthwise_conv.conv.weight - torch.Size([240, 1, 5, 5]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer6.depthwise_conv.bn.weight - torch.Size([240]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer6.depthwise_conv.bn.bias - torch.Size([240]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer6.se.conv1.conv.weight - torch.Size([64, 240, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer6.se.conv1.conv.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer6.se.conv2.conv.weight - torch.Size([240, 64, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer6.se.conv2.conv.bias - torch.Size([240]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer6.linear_conv.conv.weight - torch.Size([40, 240, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer6.linear_conv.bn.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer6.linear_conv.bn.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer7.expand_conv.conv.weight - torch.Size([120, 40, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer7.expand_conv.bn.weight - torch.Size([120]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer7.expand_conv.bn.bias - torch.Size([120]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer7.depthwise_conv.conv.weight - torch.Size([120, 1, 5, 5]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer7.depthwise_conv.bn.weight - torch.Size([120]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer7.depthwise_conv.bn.bias - torch.Size([120]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer7.se.conv1.conv.weight - torch.Size([32, 120, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer7.se.conv1.conv.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer7.se.conv2.conv.weight - torch.Size([120, 32, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer7.se.conv2.conv.bias - torch.Size([120]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer7.linear_conv.conv.weight - torch.Size([48, 120, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer7.linear_conv.bn.weight - torch.Size([48]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer7.linear_conv.bn.bias - torch.Size([48]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer8.expand_conv.conv.weight - torch.Size([144, 48, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer8.expand_conv.bn.weight - torch.Size([144]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer8.expand_conv.bn.bias - torch.Size([144]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer8.depthwise_conv.conv.weight - torch.Size([144, 1, 5, 5]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer8.depthwise_conv.bn.weight - torch.Size([144]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer8.depthwise_conv.bn.bias - torch.Size([144]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer8.se.conv1.conv.weight - torch.Size([40, 144, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer8.se.conv1.conv.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer8.se.conv2.conv.weight - torch.Size([144, 40, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer8.se.conv2.conv.bias - torch.Size([144]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer8.linear_conv.conv.weight - torch.Size([48, 144, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer8.linear_conv.bn.weight - torch.Size([48]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer8.linear_conv.bn.bias - torch.Size([48]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer9.expand_conv.conv.weight - torch.Size([288, 48, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer9.expand_conv.bn.weight - torch.Size([288]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer9.expand_conv.bn.bias - torch.Size([288]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer9.depthwise_conv.conv.weight - torch.Size([288, 1, 5, 5]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer9.depthwise_conv.bn.weight - torch.Size([288]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer9.depthwise_conv.bn.bias - torch.Size([288]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer9.se.conv1.conv.weight - torch.Size([72, 288, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer9.se.conv1.conv.bias - torch.Size([72]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer9.se.conv2.conv.weight - torch.Size([288, 72, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer9.se.conv2.conv.bias - torch.Size([288]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer9.linear_conv.conv.weight - torch.Size([96, 288, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer9.linear_conv.bn.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer9.linear_conv.bn.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer10.expand_conv.conv.weight - torch.Size([576, 96, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer10.expand_conv.bn.weight - torch.Size([576]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer10.expand_conv.bn.bias - torch.Size([576]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer10.depthwise_conv.conv.weight - torch.Size([576, 1, 5, 5]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer10.depthwise_conv.bn.weight - torch.Size([576]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer10.depthwise_conv.bn.bias - torch.Size([576]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer10.se.conv1.conv.weight - torch.Size([144, 576, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer10.se.conv1.conv.bias - torch.Size([144]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer10.se.conv2.conv.weight - torch.Size([576, 144, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer10.se.conv2.conv.bias - torch.Size([576]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer10.linear_conv.conv.weight - torch.Size([96, 576, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer10.linear_conv.bn.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer10.linear_conv.bn.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer11.expand_conv.conv.weight - torch.Size([576, 96, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer11.expand_conv.bn.weight - torch.Size([576]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer11.expand_conv.bn.bias - torch.Size([576]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer11.depthwise_conv.conv.weight - torch.Size([576, 1, 5, 5]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer11.depthwise_conv.bn.weight - torch.Size([576]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer11.depthwise_conv.bn.bias - torch.Size([576]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer11.se.conv1.conv.weight - torch.Size([144, 576, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer11.se.conv1.conv.bias - torch.Size([144]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer11.se.conv2.conv.weight - torch.Size([576, 144, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer11.se.conv2.conv.bias - torch.Size([576]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer11.linear_conv.conv.weight - torch.Size([96, 576, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer11.linear_conv.bn.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer11.linear_conv.bn.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer12.conv.weight - torch.Size([576, 96, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer12.bn.weight - torch.Size([576]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer12.bn.bias - torch.Size([576]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

head.layers.0.fc.weight - torch.Size([1024, 576]): 
NormalInit: mean=0.0, std=0.01, bias=0.0 

head.layers.0.fc.bias - torch.Size([1024]): 
NormalInit: mean=0.0, std=0.01, bias=0.0 

head.layers.1.fc.weight - torch.Size([5, 1024]): 
NormalInit: mean=0.0, std=0.01, bias=0.0 

head.layers.1.fc.bias - torch.Size([5]): 
NormalInit: mean=0.0, std=0.01, bias=0.0 
2025/05/13 08:41:18 - mmengine - INFO - Load checkpoint from work_dirs/flower_mbv3/epoch_20.pth
2025/05/13 08:41:18 - mmengine - INFO - resumed epoch: 20, iter: 1440
2025/05/13 08:41:18 - mmengine - WARNING - "FileClient" will be deprecated in future. Please use io functions in https://mmengine.readthedocs.io/en/latest/api/fileio.html#file-io
2025/05/13 08:41:18 - mmengine - WARNING - "HardDiskBackend" is the alias of "LocalBackend" and the former will be deprecated in future.
2025/05/13 08:41:18 - mmengine - INFO - Checkpoints will be saved to C:\Users\PC\mmpretrain\work_dirs\flower_mbv3.
2025/05/13 08:41:57 - mmengine - INFO - Exp name: my_flower_convnext-base_20250513_084117
2025/05/13 08:41:57 - mmengine - INFO - Epoch(train) [21][72/72]  lr: 6.1658e-04  eta: 0:12:18  time: 0.3812  data_time: 0.0010  loss: 0.4369
2025/05/13 08:41:57 - mmengine - INFO - Saving checkpoint at 21 epochs
2025/05/13 08:42:06 - mmengine - INFO - Epoch(val) [21][18/18]    accuracy/top1: 86.8881  data_time: 0.3704  time: 0.4692
2025/05/13 08:42:36 - mmengine - INFO - Exp name: my_flower_convnext-base_20250513_084117
2025/05/13 08:42:36 - mmengine - INFO - Epoch(train) [22][72/72]  lr: 6.1658e-04  eta: 0:10:22  time: 0.3751  data_time: 0.0010  loss: 0.3564
2025/05/13 08:42:36 - mmengine - INFO - Saving checkpoint at 22 epochs
2025/05/13 08:42:38 - mmengine - INFO - Epoch(val) [22][18/18]    accuracy/top1: 87.2378  data_time: 0.0029  time: 0.0977
2025/05/13 08:43:08 - mmengine - INFO - Exp name: my_flower_convnext-base_20250513_084117
2025/05/13 08:43:08 - mmengine - INFO - Epoch(train) [23][72/72]  lr: 6.1658e-04  eta: 0:09:18  time: 0.3856  data_time: 0.0011  loss: 0.4094
2025/05/13 08:43:08 - mmengine - INFO - Saving checkpoint at 23 epochs
2025/05/13 08:43:09 - mmengine - INFO - Epoch(val) [23][18/18]    accuracy/top1: 86.7133  data_time: 0.0028  time: 0.0962
2025/05/13 08:43:39 - mmengine - INFO - Exp name: my_flower_convnext-base_20250513_084117
2025/05/13 08:43:39 - mmengine - INFO - Epoch(train) [24][72/72]  lr: 6.1658e-04  eta: 0:08:33  time: 0.3826  data_time: 0.0012  loss: 0.3359
2025/05/13 08:43:39 - mmengine - INFO - Saving checkpoint at 24 epochs
2025/05/13 08:43:41 - mmengine - INFO - Epoch(val) [24][18/18]    accuracy/top1: 86.5385  data_time: 0.0030  time: 0.0988
2025/05/13 08:44:11 - mmengine - INFO - Exp name: my_flower_convnext-base_20250513_084117
2025/05/13 08:44:11 - mmengine - INFO - Epoch(train) [25][72/72]  lr: 6.1658e-04  eta: 0:07:54  time: 0.3744  data_time: 0.0007  loss: 0.5275
2025/05/13 08:44:11 - mmengine - INFO - Saving checkpoint at 25 epochs
2025/05/13 08:44:13 - mmengine - INFO - Epoch(val) [25][18/18]    accuracy/top1: 86.7133  data_time: 0.0027  time: 0.0957
2025/05/13 08:44:43 - mmengine - INFO - Exp name: my_flower_convnext-base_20250513_084117
2025/05/13 08:44:43 - mmengine - INFO - Epoch(train) [26][72/72]  lr: 6.1658e-04  eta: 0:07:18  time: 0.3633  data_time: 0.0013  loss: 0.3368
2025/05/13 08:44:43 - mmengine - INFO - Saving checkpoint at 26 epochs
2025/05/13 08:44:45 - mmengine - INFO - Epoch(val) [26][18/18]    accuracy/top1: 86.7133  data_time: 0.0035  time: 0.0964
2025/05/13 08:45:14 - mmengine - INFO - Exp name: my_flower_convnext-base_20250513_084117
2025/05/13 08:45:14 - mmengine - INFO - Epoch(train) [27][72/72]  lr: 6.1554e-04  eta: 0:06:44  time: 0.3661  data_time: 0.0012  loss: 0.3664
2025/05/13 08:45:14 - mmengine - INFO - Saving checkpoint at 27 epochs
2025/05/13 08:45:16 - mmengine - INFO - Epoch(val) [27][18/18]    accuracy/top1: 86.5385  data_time: 0.0029  time: 0.0969
2025/05/13 08:45:39 - mmengine - INFO - Exp name: my_flower_convnext-base_20250513_084117
2025/05/13 08:45:46 - mmengine - INFO - Exp name: my_flower_convnext-base_20250513_084117
2025/05/13 08:45:46 - mmengine - INFO - Epoch(train) [28][72/72]  lr: 6.1243e-04  eta: 0:06:10  time: 0.3633  data_time: 0.0012  loss: 0.3943
2025/05/13 08:45:46 - mmengine - INFO - Saving checkpoint at 28 epochs
2025/05/13 08:45:47 - mmengine - INFO - Epoch(val) [28][18/18]    accuracy/top1: 86.7133  data_time: 0.0029  time: 0.0984
2025/05/13 08:46:17 - mmengine - INFO - Exp name: my_flower_convnext-base_20250513_084117
2025/05/13 08:46:17 - mmengine - INFO - Epoch(train) [29][72/72]  lr: 6.0727e-04  eta: 0:05:38  time: 0.3749  data_time: 0.0011  loss: 0.4096
2025/05/13 08:46:17 - mmengine - INFO - Saving checkpoint at 29 epochs
2025/05/13 08:46:19 - mmengine - INFO - Epoch(val) [29][18/18]    accuracy/top1: 86.5385  data_time: 0.0029  time: 0.0977
2025/05/13 08:46:48 - mmengine - INFO - Exp name: my_flower_convnext-base_20250513_084117
2025/05/13 08:46:48 - mmengine - INFO - Epoch(train) [30][72/72]  lr: 6.0011e-04  eta: 0:05:06  time: 0.3760  data_time: 0.0011  loss: 0.3844
2025/05/13 08:46:48 - mmengine - INFO - Saving checkpoint at 30 epochs
2025/05/13 08:46:50 - mmengine - INFO - Epoch(val) [30][18/18]    accuracy/top1: 86.7133  data_time: 0.0032  time: 0.0965
2025/05/13 08:47:20 - mmengine - INFO - Exp name: my_flower_convnext-base_20250513_084117
2025/05/13 08:47:20 - mmengine - INFO - Epoch(train) [31][72/72]  lr: 5.9100e-04  eta: 0:04:34  time: 0.3843  data_time: 0.0011  loss: 0.3998
2025/05/13 08:47:20 - mmengine - INFO - Saving checkpoint at 31 epochs
2025/05/13 08:47:22 - mmengine - INFO - Epoch(val) [31][18/18]    accuracy/top1: 86.3636  data_time: 0.0029  time: 0.0952
2025/05/13 08:47:52 - mmengine - INFO - Exp name: my_flower_convnext-base_20250513_084117
2025/05/13 08:47:52 - mmengine - INFO - Epoch(train) [32][72/72]  lr: 5.8002e-04  eta: 0:04:03  time: 0.3836  data_time: 0.0008  loss: 0.3760
2025/05/13 08:47:52 - mmengine - INFO - Saving checkpoint at 32 epochs
2025/05/13 08:47:54 - mmengine - INFO - Epoch(val) [32][18/18]    accuracy/top1: 86.1888  data_time: 0.0032  time: 0.0979
2025/05/13 08:48:23 - mmengine - INFO - Exp name: my_flower_convnext-base_20250513_084117
2025/05/13 08:48:23 - mmengine - INFO - Epoch(train) [33][72/72]  lr: 5.6725e-04  eta: 0:03:32  time: 0.3730  data_time: 0.0012  loss: 0.2994
2025/05/13 08:48:23 - mmengine - INFO - Saving checkpoint at 33 epochs
2025/05/13 08:48:25 - mmengine - INFO - Epoch(val) [33][18/18]    accuracy/top1: 86.1888  data_time: 0.0029  time: 0.0964
2025/05/13 08:48:55 - mmengine - INFO - Exp name: my_flower_convnext-base_20250513_084117
2025/05/13 08:48:55 - mmengine - INFO - Epoch(train) [34][72/72]  lr: 5.5280e-04  eta: 0:03:02  time: 0.3752  data_time: 0.0012  loss: 0.4149
2025/05/13 08:48:55 - mmengine - INFO - Saving checkpoint at 34 epochs
2025/05/13 08:48:56 - mmengine - INFO - Epoch(val) [34][18/18]    accuracy/top1: 86.3636  data_time: 0.0030  time: 0.0934
2025/05/13 08:49:26 - mmengine - INFO - Exp name: my_flower_convnext-base_20250513_084117
2025/05/13 08:49:26 - mmengine - INFO - Epoch(train) [35][72/72]  lr: 5.3678e-04  eta: 0:02:31  time: 0.3684  data_time: 0.0011  loss: 0.3599
2025/05/13 08:49:26 - mmengine - INFO - Saving checkpoint at 35 epochs
2025/05/13 08:49:28 - mmengine - INFO - Epoch(val) [35][18/18]    accuracy/top1: 86.5385  data_time: 0.0031  time: 0.0964
2025/05/13 08:49:57 - mmengine - INFO - Exp name: my_flower_convnext-base_20250513_084117
2025/05/13 08:49:57 - mmengine - INFO - Epoch(train) [36][72/72]  lr: 5.1933e-04  eta: 0:02:00  time: 0.3824  data_time: 0.0012  loss: 0.3269
2025/05/13 08:49:57 - mmengine - INFO - Saving checkpoint at 36 epochs
2025/05/13 08:49:59 - mmengine - INFO - Epoch(val) [36][18/18]    accuracy/top1: 86.8881  data_time: 0.0031  time: 0.0963
2025/05/13 08:50:29 - mmengine - INFO - Exp name: my_flower_convnext-base_20250513_084117
2025/05/13 08:50:29 - mmengine - INFO - Epoch(train) [37][72/72]  lr: 5.0058e-04  eta: 0:01:30  time: 0.3791  data_time: 0.0012  loss: 0.5538
2025/05/13 08:50:29 - mmengine - INFO - Saving checkpoint at 37 epochs
2025/05/13 08:50:31 - mmengine - INFO - Epoch(val) [37][18/18]    accuracy/top1: 86.8881  data_time: 0.0032  time: 0.0978
2025/05/13 08:51:02 - mmengine - INFO - Exp name: my_flower_convnext-base_20250513_084117
2025/05/13 08:51:02 - mmengine - INFO - Epoch(train) [38][72/72]  lr: 4.8068e-04  eta: 0:01:00  time: 0.4004  data_time: 0.0010  loss: 0.3557
2025/05/13 08:51:02 - mmengine - INFO - Saving checkpoint at 38 epochs
2025/05/13 08:51:04 - mmengine - INFO - Epoch(val) [38][18/18]    accuracy/top1: 86.7133  data_time: 0.0031  time: 0.0989
2025/05/13 08:51:36 - mmengine - INFO - Exp name: my_flower_convnext-base_20250513_084117
2025/05/13 08:51:36 - mmengine - INFO - Epoch(train) [39][72/72]  lr: 4.5980e-04  eta: 0:00:30  time: 0.4166  data_time: 0.0014  loss: 0.3366
2025/05/13 08:51:36 - mmengine - INFO - Saving checkpoint at 39 epochs
2025/05/13 08:51:38 - mmengine - INFO - Epoch(val) [39][18/18]    accuracy/top1: 86.7133  data_time: 0.0032  time: 0.1056
2025/05/13 08:52:09 - mmengine - INFO - Exp name: my_flower_convnext-base_20250513_084117
2025/05/13 08:52:09 - mmengine - INFO - Epoch(train) [40][72/72]  lr: 4.3810e-04  eta: 0:00:00  time: 0.4036  data_time: 0.0012  loss: 0.3624
2025/05/13 08:52:09 - mmengine - INFO - Saving checkpoint at 40 epochs
2025/05/13 08:52:11 - mmengine - INFO - Epoch(val) [40][18/18]    accuracy/top1: 86.1888  data_time: 0.0029  time: 0.1016
