2025/05/13 08:53:05 - mmengine - INFO - 
------------------------------------------------------------
System environment:
    sys.platform: win32
    Python: 3.8.20 | packaged by conda-forge | (default, Sep 30 2024, 17:44:03) [MSC v.1929 64 bit (AMD64)]
    CUDA available: False
    MUSA available: False
    numpy_random_seed: 1351954111
    GCC: n/a
    PyTorch: 2.2.2+cpu
    PyTorch compiling details: PyTorch built with:
  - C++ Version: 201703
  - MSVC 192930151
  - Intel(R) Math Kernel Library Version 2020.0.2 Product Build 20200624 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.3.2 (Git Hash 2dc95a2ad0841e29db8b22fbccaf3e5da7992b01)
  - OpenMP 2019
  - LAPACK is enabled (usually provided by MKL)
  - CPU capability usage: AVX2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CXX_COMPILER=C:/actions-runner/_work/pytorch/pytorch/builder/windows/tmp_bin/sccache-cl.exe, CXX_FLAGS=/DWIN32 /D_WINDOWS /GR /EHsc /Zc:__cplusplus /bigobj /FS /utf-8 -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOCUPTI -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE /wd4624 /wd4068 /wd4067 /wd4267 /wd4661 /wd4717 /wd4244 /wd4804 /wd4273, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.2.2, USE_CUDA=0, USE_CUDNN=OFF, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=OFF, USE_NNPACK=OFF, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

    TorchVision: 0.17.2+cpu
    OpenCV: 4.11.0
    MMEngine: 0.10.7

Runtime environment:
    cudnn_benchmark: False
    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}
    dist_cfg: {'backend': 'nccl'}
    seed: 1351954111
    deterministic: False
    Distributed launcher: none
    Distributed training: False
    GPU number: 1
------------------------------------------------------------

2025/05/13 08:53:05 - mmengine - INFO - Config:
auto_scale_lr = dict(base_batch_size=256)
default_hooks = dict(
    checkpoint=dict(interval=1, type='CheckpointHook'),
    logger=dict(interval=100, type='LoggerHook'),
    param_scheduler=dict(type='ParamSchedulerHook'),
    sampler_seed=dict(type='DistSamplerSeedHook'),
    timer=dict(type='IterTimerHook'),
    visualization=dict(enable=False, type='VisualizationHook'))
default_scope = 'mmpretrain'
env_cfg = dict(
    cudnn_benchmark=False,
    dist_cfg=dict(backend='nccl'),
    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))
launcher = 'none'
load_from = 'checkpoints/mobilenet-v3-small_8xb128_in1k_20221114-bd1bfcde.pth'
log_level = 'INFO'
model = dict(
    backbone=dict(arch='small', type='MobileNetV3'),
    head=dict(
        act_cfg=dict(type='HSwish'),
        dropout_rate=0.2,
        in_channels=576,
        init_cfg=dict(
            bias=0.0, layer='Linear', mean=0.0, std=0.01, type='Normal'),
        loss=dict(loss_weight=1.0, type='CrossEntropyLoss'),
        mid_channels=[
            1024,
        ],
        num_classes=5,
        topk=(1, ),
        type='StackedLinearClsHead'),
    neck=dict(type='GlobalAveragePooling'),
    type='ImageClassifier')
optim_wrapper = dict(
    optimizer=dict(lr=0.1, momentum=0.9, type='SGD', weight_decay=0.0001))
optimizer = dict(
    betas=(
        0.9,
        0.999,
    ), lr=0.01, type='AdamW', weight_decay=0.05)
param_scheduler = [
    dict(begin=0, by_epoch=True, end=5, start_factor=0.1, type='LinearLR'),
    dict(
        T_max=35,
        begin=5,
        by_epoch=True,
        end=40,
        eta_min=0.0001,
        type='CosineAnnealingLR'),
]
randomness = dict(deterministic=False, seed=None)
resume = False
test_cfg = dict()
test_dataloader = dict(
    batch_size=32,
    collate_fn=dict(type='default_collate'),
    dataset=dict(
        classes='data/flower_dataset/classes.txt',
        data_prefix='val',
        data_root='data/flower_dataset',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(edge='short', scale=256, type='ResizeEdge'),
            dict(crop_size=224, type='CenterCrop'),
            dict(type='PackInputs'),
        ],
        type='ImageNet'),
    num_workers=4,
    persistent_workers=True,
    pin_memory=True,
    sampler=dict(shuffle=False, type='DefaultSampler'))
test_evaluator = dict(topk=(1, ), type='Accuracy')
test_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(edge='short', scale=256, type='ResizeEdge'),
    dict(crop_size=224, type='CenterCrop'),
    dict(type='PackInputs'),
]
train_cfg = dict(by_epoch=True, max_epochs=40, val_interval=1)
train_dataloader = dict(
    batch_size=32,
    collate_fn=dict(type='default_collate'),
    dataset=dict(
        classes='data/flower_dataset/classes.txt',
        data_prefix='train',
        data_root='data/flower_dataset',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(scale=224, type='RandomResizedCrop'),
            dict(direction='horizontal', prob=0.5, type='RandomFlip'),
            dict(type='PackInputs'),
        ],
        type='ImageNet'),
    num_workers=4,
    persistent_workers=True,
    pin_memory=True,
    sampler=dict(shuffle=True, type='DefaultSampler'))
train_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(scale=224, type='RandomResizedCrop'),
    dict(direction='horizontal', prob=0.5, type='RandomFlip'),
    dict(type='PackInputs'),
]
val_cfg = dict()
val_dataloader = dict(
    batch_size=32,
    collate_fn=dict(type='default_collate'),
    dataset=dict(
        classes='data/flower_dataset/classes.txt',
        data_prefix='val',
        data_root='data/flower_dataset',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(edge='short', scale=256, type='ResizeEdge'),
            dict(crop_size=224, type='CenterCrop'),
            dict(type='PackInputs'),
        ],
        type='ImageNet'),
    num_workers=4,
    persistent_workers=True,
    pin_memory=True,
    sampler=dict(shuffle=False, type='DefaultSampler'))
val_evaluator = dict(topk=(1, ), type='Accuracy')
vis_backends = [
    dict(type='LocalVisBackend'),
]
visualizer = dict(
    type='UniversalVisualizer', vis_backends=[
        dict(type='LocalVisBackend'),
    ])
work_dir = 'work_dirs/flower_mbv3'

2025/05/13 08:53:05 - mmengine - INFO - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.
2025/05/13 08:53:05 - mmengine - INFO - Hooks will be executed in the following order:
before_run:
(VERY_HIGH   ) RuntimeInfoHook                    
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
before_train:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_train_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(NORMAL      ) DistSamplerSeedHook                
 -------------------- 
before_train_iter:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_train_iter:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
after_train_epoch:
(NORMAL      ) IterTimerHook                      
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_val:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
before_val_epoch:
(NORMAL      ) IterTimerHook                      
 -------------------- 
before_val_iter:
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_val_iter:
(NORMAL      ) IterTimerHook                      
(NORMAL      ) VisualizationHook                  
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_val_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
after_val:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
after_train:
(VERY_HIGH   ) RuntimeInfoHook                    
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_test:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
before_test_epoch:
(NORMAL      ) IterTimerHook                      
 -------------------- 
before_test_iter:
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_test_iter:
(NORMAL      ) IterTimerHook                      
(NORMAL      ) VisualizationHook                  
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_test_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_test:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
after_run:
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
Name of parameter - Initialization information

backbone.layer0.conv.weight - torch.Size([16, 3, 3, 3]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer0.bn.weight - torch.Size([16]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer0.bn.bias - torch.Size([16]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer1.depthwise_conv.conv.weight - torch.Size([16, 1, 3, 3]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer1.depthwise_conv.bn.weight - torch.Size([16]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer1.depthwise_conv.bn.bias - torch.Size([16]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer1.se.conv1.conv.weight - torch.Size([8, 16, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer1.se.conv1.conv.bias - torch.Size([8]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer1.se.conv2.conv.weight - torch.Size([16, 8, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer1.se.conv2.conv.bias - torch.Size([16]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer1.linear_conv.conv.weight - torch.Size([16, 16, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer1.linear_conv.bn.weight - torch.Size([16]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer1.linear_conv.bn.bias - torch.Size([16]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer2.expand_conv.conv.weight - torch.Size([72, 16, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer2.expand_conv.bn.weight - torch.Size([72]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer2.expand_conv.bn.bias - torch.Size([72]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer2.depthwise_conv.conv.weight - torch.Size([72, 1, 3, 3]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer2.depthwise_conv.bn.weight - torch.Size([72]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer2.depthwise_conv.bn.bias - torch.Size([72]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer2.linear_conv.conv.weight - torch.Size([24, 72, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer2.linear_conv.bn.weight - torch.Size([24]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer2.linear_conv.bn.bias - torch.Size([24]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.expand_conv.conv.weight - torch.Size([88, 24, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer3.expand_conv.bn.weight - torch.Size([88]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.expand_conv.bn.bias - torch.Size([88]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.depthwise_conv.conv.weight - torch.Size([88, 1, 3, 3]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer3.depthwise_conv.bn.weight - torch.Size([88]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.depthwise_conv.bn.bias - torch.Size([88]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.linear_conv.conv.weight - torch.Size([24, 88, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer3.linear_conv.bn.weight - torch.Size([24]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer3.linear_conv.bn.bias - torch.Size([24]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer4.expand_conv.conv.weight - torch.Size([96, 24, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer4.expand_conv.bn.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer4.expand_conv.bn.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer4.depthwise_conv.conv.weight - torch.Size([96, 1, 5, 5]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer4.depthwise_conv.bn.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer4.depthwise_conv.bn.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer4.se.conv1.conv.weight - torch.Size([24, 96, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer4.se.conv1.conv.bias - torch.Size([24]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer4.se.conv2.conv.weight - torch.Size([96, 24, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer4.se.conv2.conv.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer4.linear_conv.conv.weight - torch.Size([40, 96, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer4.linear_conv.bn.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer4.linear_conv.bn.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer5.expand_conv.conv.weight - torch.Size([240, 40, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer5.expand_conv.bn.weight - torch.Size([240]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer5.expand_conv.bn.bias - torch.Size([240]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer5.depthwise_conv.conv.weight - torch.Size([240, 1, 5, 5]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer5.depthwise_conv.bn.weight - torch.Size([240]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer5.depthwise_conv.bn.bias - torch.Size([240]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer5.se.conv1.conv.weight - torch.Size([64, 240, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer5.se.conv1.conv.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer5.se.conv2.conv.weight - torch.Size([240, 64, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer5.se.conv2.conv.bias - torch.Size([240]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer5.linear_conv.conv.weight - torch.Size([40, 240, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer5.linear_conv.bn.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer5.linear_conv.bn.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer6.expand_conv.conv.weight - torch.Size([240, 40, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer6.expand_conv.bn.weight - torch.Size([240]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer6.expand_conv.bn.bias - torch.Size([240]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer6.depthwise_conv.conv.weight - torch.Size([240, 1, 5, 5]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer6.depthwise_conv.bn.weight - torch.Size([240]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer6.depthwise_conv.bn.bias - torch.Size([240]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer6.se.conv1.conv.weight - torch.Size([64, 240, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer6.se.conv1.conv.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer6.se.conv2.conv.weight - torch.Size([240, 64, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer6.se.conv2.conv.bias - torch.Size([240]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer6.linear_conv.conv.weight - torch.Size([40, 240, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer6.linear_conv.bn.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer6.linear_conv.bn.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer7.expand_conv.conv.weight - torch.Size([120, 40, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer7.expand_conv.bn.weight - torch.Size([120]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer7.expand_conv.bn.bias - torch.Size([120]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer7.depthwise_conv.conv.weight - torch.Size([120, 1, 5, 5]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer7.depthwise_conv.bn.weight - torch.Size([120]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer7.depthwise_conv.bn.bias - torch.Size([120]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer7.se.conv1.conv.weight - torch.Size([32, 120, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer7.se.conv1.conv.bias - torch.Size([32]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer7.se.conv2.conv.weight - torch.Size([120, 32, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer7.se.conv2.conv.bias - torch.Size([120]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer7.linear_conv.conv.weight - torch.Size([48, 120, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer7.linear_conv.bn.weight - torch.Size([48]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer7.linear_conv.bn.bias - torch.Size([48]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer8.expand_conv.conv.weight - torch.Size([144, 48, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer8.expand_conv.bn.weight - torch.Size([144]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer8.expand_conv.bn.bias - torch.Size([144]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer8.depthwise_conv.conv.weight - torch.Size([144, 1, 5, 5]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer8.depthwise_conv.bn.weight - torch.Size([144]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer8.depthwise_conv.bn.bias - torch.Size([144]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer8.se.conv1.conv.weight - torch.Size([40, 144, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer8.se.conv1.conv.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer8.se.conv2.conv.weight - torch.Size([144, 40, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer8.se.conv2.conv.bias - torch.Size([144]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer8.linear_conv.conv.weight - torch.Size([48, 144, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer8.linear_conv.bn.weight - torch.Size([48]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer8.linear_conv.bn.bias - torch.Size([48]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer9.expand_conv.conv.weight - torch.Size([288, 48, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer9.expand_conv.bn.weight - torch.Size([288]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer9.expand_conv.bn.bias - torch.Size([288]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer9.depthwise_conv.conv.weight - torch.Size([288, 1, 5, 5]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer9.depthwise_conv.bn.weight - torch.Size([288]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer9.depthwise_conv.bn.bias - torch.Size([288]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer9.se.conv1.conv.weight - torch.Size([72, 288, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer9.se.conv1.conv.bias - torch.Size([72]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer9.se.conv2.conv.weight - torch.Size([288, 72, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer9.se.conv2.conv.bias - torch.Size([288]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer9.linear_conv.conv.weight - torch.Size([96, 288, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer9.linear_conv.bn.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer9.linear_conv.bn.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer10.expand_conv.conv.weight - torch.Size([576, 96, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer10.expand_conv.bn.weight - torch.Size([576]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer10.expand_conv.bn.bias - torch.Size([576]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer10.depthwise_conv.conv.weight - torch.Size([576, 1, 5, 5]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer10.depthwise_conv.bn.weight - torch.Size([576]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer10.depthwise_conv.bn.bias - torch.Size([576]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer10.se.conv1.conv.weight - torch.Size([144, 576, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer10.se.conv1.conv.bias - torch.Size([144]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer10.se.conv2.conv.weight - torch.Size([576, 144, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer10.se.conv2.conv.bias - torch.Size([576]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer10.linear_conv.conv.weight - torch.Size([96, 576, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer10.linear_conv.bn.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer10.linear_conv.bn.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer11.expand_conv.conv.weight - torch.Size([576, 96, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer11.expand_conv.bn.weight - torch.Size([576]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer11.expand_conv.bn.bias - torch.Size([576]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer11.depthwise_conv.conv.weight - torch.Size([576, 1, 5, 5]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer11.depthwise_conv.bn.weight - torch.Size([576]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer11.depthwise_conv.bn.bias - torch.Size([576]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer11.se.conv1.conv.weight - torch.Size([144, 576, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer11.se.conv1.conv.bias - torch.Size([144]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer11.se.conv2.conv.weight - torch.Size([576, 144, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer11.se.conv2.conv.bias - torch.Size([576]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer11.linear_conv.conv.weight - torch.Size([96, 576, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer11.linear_conv.bn.weight - torch.Size([96]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer11.linear_conv.bn.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer12.conv.weight - torch.Size([576, 96, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.layer12.bn.weight - torch.Size([576]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

backbone.layer12.bn.bias - torch.Size([576]): 
The value is the same before and after calling `init_weights` of ImageClassifier  

head.layers.0.fc.weight - torch.Size([1024, 576]): 
NormalInit: mean=0.0, std=0.01, bias=0.0 

head.layers.0.fc.bias - torch.Size([1024]): 
NormalInit: mean=0.0, std=0.01, bias=0.0 

head.layers.1.fc.weight - torch.Size([5, 1024]): 
NormalInit: mean=0.0, std=0.01, bias=0.0 

head.layers.1.fc.bias - torch.Size([5]): 
NormalInit: mean=0.0, std=0.01, bias=0.0 
2025/05/13 08:53:06 - mmengine - INFO - Load checkpoint from checkpoints/mobilenet-v3-small_8xb128_in1k_20221114-bd1bfcde.pth
2025/05/13 08:53:06 - mmengine - WARNING - "FileClient" will be deprecated in future. Please use io functions in https://mmengine.readthedocs.io/en/latest/api/fileio.html#file-io
2025/05/13 08:53:06 - mmengine - WARNING - "HardDiskBackend" is the alias of "LocalBackend" and the former will be deprecated in future.
2025/05/13 08:53:06 - mmengine - INFO - Checkpoints will be saved to C:\Users\PC\mmpretrain\work_dirs\flower_mbv3.
2025/05/13 08:53:44 - mmengine - INFO - Exp name: my_flower_convnext-base_20250513_085305
2025/05/13 08:53:44 - mmengine - INFO - Epoch(train)  [1][72/72]  lr: 1.0000e-02  eta: 0:24:56  time: 0.3951  data_time: 0.0011  loss: 0.5537
2025/05/13 08:53:44 - mmengine - INFO - Saving checkpoint at 1 epochs
2025/05/13 08:53:54 - mmengine - INFO - Epoch(val) [1][18/18]    accuracy/top1: 68.1818  data_time: 0.4188  time: 0.5266
2025/05/13 08:54:26 - mmengine - INFO - Exp name: my_flower_convnext-base_20250513_085305
2025/05/13 08:54:26 - mmengine - INFO - Epoch(train)  [2][72/72]  lr: 3.2500e-02  eta: 0:22:19  time: 0.4098  data_time: 0.0013  loss: 0.6390
2025/05/13 08:54:26 - mmengine - INFO - Saving checkpoint at 2 epochs
2025/05/13 08:54:28 - mmengine - INFO - Epoch(val) [2][18/18]    accuracy/top1: 58.3916  data_time: 0.0033  time: 0.1063
2025/05/13 08:55:00 - mmengine - INFO - Exp name: my_flower_convnext-base_20250513_085305
2025/05/13 08:55:00 - mmengine - INFO - Epoch(train)  [3][72/72]  lr: 5.5000e-02  eta: 0:20:58  time: 0.3998  data_time: 0.0010  loss: 1.3268
2025/05/13 08:55:00 - mmengine - INFO - Saving checkpoint at 3 epochs
2025/05/13 08:55:02 - mmengine - INFO - Epoch(val) [3][18/18]    accuracy/top1: 19.9301  data_time: 0.0033  time: 0.1080
2025/05/13 08:55:33 - mmengine - INFO - Exp name: my_flower_convnext-base_20250513_085305
2025/05/13 08:55:33 - mmengine - INFO - Epoch(train)  [4][72/72]  lr: 7.7500e-02  eta: 0:20:01  time: 0.3934  data_time: 0.0012  loss: 1.2805
2025/05/13 08:55:33 - mmengine - INFO - Saving checkpoint at 4 epochs
2025/05/13 08:55:35 - mmengine - INFO - Epoch(val) [4][18/18]    accuracy/top1: 26.0490  data_time: 0.0029  time: 0.1044
2025/05/13 08:56:06 - mmengine - INFO - Exp name: my_flower_convnext-base_20250513_085305
2025/05/13 08:56:06 - mmengine - INFO - Epoch(train)  [5][72/72]  lr: 1.0000e-01  eta: 0:19:11  time: 0.3865  data_time: 0.0011  loss: 1.5806
2025/05/13 08:56:06 - mmengine - INFO - Saving checkpoint at 5 epochs
2025/05/13 08:56:08 - mmengine - INFO - Epoch(val) [5][18/18]    accuracy/top1: 22.2028  data_time: 0.0029  time: 0.1040
2025/05/13 08:56:40 - mmengine - INFO - Exp name: my_flower_convnext-base_20250513_085305
2025/05/13 08:56:40 - mmengine - INFO - Epoch(train)  [6][72/72]  lr: 1.0000e-01  eta: 0:18:31  time: 0.4001  data_time: 0.0012  loss: 0.8650
2025/05/13 08:56:40 - mmengine - INFO - Saving checkpoint at 6 epochs
2025/05/13 08:56:42 - mmengine - INFO - Epoch(val) [6][18/18]    accuracy/top1: 55.7692  data_time: 0.0033  time: 0.1039
2025/05/13 08:57:13 - mmengine - INFO - Exp name: my_flower_convnext-base_20250513_085305
2025/05/13 08:57:13 - mmengine - INFO - Epoch(train)  [7][72/72]  lr: 9.9799e-02  eta: 0:17:53  time: 0.4075  data_time: 0.0014  loss: 0.8250
2025/05/13 08:57:13 - mmengine - INFO - Saving checkpoint at 7 epochs
2025/05/13 08:57:16 - mmengine - INFO - Epoch(val) [7][18/18]    accuracy/top1: 44.2308  data_time: 0.0030  time: 0.1064
2025/05/13 08:57:47 - mmengine - INFO - Exp name: my_flower_convnext-base_20250513_085305
2025/05/13 08:57:47 - mmengine - INFO - Epoch(train)  [8][72/72]  lr: 9.9197e-02  eta: 0:17:17  time: 0.4061  data_time: 0.0013  loss: 0.6926
2025/05/13 08:57:47 - mmengine - INFO - Saving checkpoint at 8 epochs
2025/05/13 08:57:49 - mmengine - INFO - Epoch(val) [8][18/18]    accuracy/top1: 79.0210  data_time: 0.0031  time: 0.1096
2025/05/13 08:58:21 - mmengine - INFO - Exp name: my_flower_convnext-base_20250513_085305
2025/05/13 08:58:21 - mmengine - INFO - Epoch(train)  [9][72/72]  lr: 9.8200e-02  eta: 0:16:40  time: 0.3753  data_time: 0.0011  loss: 0.4754
2025/05/13 08:58:21 - mmengine - INFO - Saving checkpoint at 9 epochs
2025/05/13 08:58:23 - mmengine - INFO - Epoch(val) [9][18/18]    accuracy/top1: 79.3706  data_time: 0.0032  time: 0.1005
2025/05/13 08:58:53 - mmengine - INFO - Exp name: my_flower_convnext-base_20250513_085305
2025/05/13 08:58:53 - mmengine - INFO - Epoch(train) [10][72/72]  lr: 9.6815e-02  eta: 0:16:02  time: 0.3913  data_time: 0.0011  loss: 0.6054
2025/05/13 08:58:53 - mmengine - INFO - Saving checkpoint at 10 epochs
2025/05/13 08:58:55 - mmengine - INFO - Epoch(val) [10][18/18]    accuracy/top1: 68.7063  data_time: 0.0032  time: 0.1005
2025/05/13 08:59:27 - mmengine - INFO - Exp name: my_flower_convnext-base_20250513_085305
2025/05/13 08:59:27 - mmengine - INFO - Epoch(train) [11][72/72]  lr: 9.5053e-02  eta: 0:15:30  time: 0.4085  data_time: 0.0013  loss: 0.5367
2025/05/13 08:59:27 - mmengine - INFO - Saving checkpoint at 11 epochs
2025/05/13 08:59:29 - mmengine - INFO - Epoch(val) [11][18/18]    accuracy/top1: 74.8252  data_time: 0.0033  time: 0.1036
2025/05/13 09:00:01 - mmengine - INFO - Exp name: my_flower_convnext-base_20250513_085305
2025/05/13 09:00:01 - mmengine - INFO - Epoch(train) [12][72/72]  lr: 9.2930e-02  eta: 0:14:58  time: 0.4067  data_time: 0.0010  loss: 0.4977
2025/05/13 09:00:01 - mmengine - INFO - Saving checkpoint at 12 epochs
2025/05/13 09:00:03 - mmengine - INFO - Epoch(val) [12][18/18]    accuracy/top1: 81.8182  data_time: 0.0032  time: 0.1032
2025/05/13 09:00:35 - mmengine - INFO - Exp name: my_flower_convnext-base_20250513_085305
2025/05/13 09:00:35 - mmengine - INFO - Epoch(train) [13][72/72]  lr: 9.0460e-02  eta: 0:14:25  time: 0.3981  data_time: 0.0011  loss: 0.6707
2025/05/13 09:00:35 - mmengine - INFO - Saving checkpoint at 13 epochs
2025/05/13 09:00:37 - mmengine - INFO - Epoch(val) [13][18/18]    accuracy/top1: 69.9301  data_time: 0.0031  time: 0.1101
2025/05/13 09:01:05 - mmengine - INFO - Exp name: my_flower_convnext-base_20250513_085305
2025/05/13 09:01:08 - mmengine - INFO - Exp name: my_flower_convnext-base_20250513_085305
2025/05/13 09:01:08 - mmengine - INFO - Epoch(train) [14][72/72]  lr: 8.7666e-02  eta: 0:13:51  time: 0.3995  data_time: 0.0010  loss: 0.4340
2025/05/13 09:01:08 - mmengine - INFO - Saving checkpoint at 14 epochs
2025/05/13 09:01:10 - mmengine - INFO - Epoch(val) [14][18/18]    accuracy/top1: 84.0909  data_time: 0.0034  time: 0.1002
2025/05/13 09:01:41 - mmengine - INFO - Exp name: my_flower_convnext-base_20250513_085305
2025/05/13 09:01:41 - mmengine - INFO - Epoch(train) [15][72/72]  lr: 8.4569e-02  eta: 0:13:18  time: 0.3804  data_time: 0.0011  loss: 0.3938
2025/05/13 09:01:41 - mmengine - INFO - Saving checkpoint at 15 epochs
2025/05/13 09:01:43 - mmengine - INFO - Epoch(val) [15][18/18]    accuracy/top1: 80.2448  data_time: 0.0030  time: 0.1017
